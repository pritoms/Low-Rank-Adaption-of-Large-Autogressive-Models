{
    "model_type": "roberta",
    "dataset": "webtext",
    "model_name_or_path": "roberta-base",
    "output_dir": "./workdir/",
    "do_train": true,
    "do_eval": true,
    "max_seq_length": 256,
    "num_train_epochs": 100,
    "per_gpu_train_batch_size": 32,
    "per_gpu_eval_batch_size": 32,
    "learning_rate": 1e-4,
    "weight_decay": 1e-3,
    "warmup_steps": 4000,
    "save_steps": 1000,
    "eval_steps": 50,
}
